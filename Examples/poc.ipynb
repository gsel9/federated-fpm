{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6617d2-2952-4ffb-a4b0-5972899444b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 13:37:56.289281: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9fd292-6df9-47d6-b2b6-56b4e065c01b",
   "metadata": {},
   "source": [
    "# Centralized setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "81bedd8e-9672-4261-8e73-a810cbda2a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((148, 78), (50, 78))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sksurv.datasets import load_breast_cancer \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset \n",
    "X, y = load_breast_cancer()\n",
    "\n",
    "# Unpack \n",
    "event, duration = zip(*y)\n",
    "e = np.array(event)\n",
    "t = np.array(duration)\n",
    "\n",
    "# Drop columns that are not numerical \n",
    "X = X[X.columns[X.dtypes != \"category\"]]\n",
    "\n",
    "# Train-test splitting \n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(X.shape[0]), test_size=0.25, random_state=42, stratify=e.astype(int)\n",
    ")\n",
    "X_train, X_test = X.iloc[train_idx].to_numpy(), X.iloc[test_idx].to_numpy()\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "e_train, e_test = e[train_idx], e[test_idx]\n",
    "t_train, t_test = t[train_idx], t[test_idx]\n",
    "\n",
    "X_train.shape, X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0b37b6c9-165c-4727-9813-7e5f7edfd3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c6f1b0d4-c09a-46e1-a0ae-2d3435cb75ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.82831374, 7.77267739, 8.38569183, 8.62443073, 9.11690843])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.log(t_train)\n",
    "x_test = np.log(t_test)\n",
    "\n",
    "knots = np.percentile(x, [0, 25, 50, 75, 100])\n",
    "knots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "61e0bb3b-b5e5-4cfc-aed7-00849f01f11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 5)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spline_basis(x, knots, j):\n",
    "    k_min = min(knots)\n",
    "    k_max = max(knots)\n",
    "    phi = (k_max - knots[j]) / (k_max - k_min)\n",
    "    return np.maximum(0, x - knots[j]) ** 3 - phi * np.maximum(0, x - k_min) ** 3 - (1 - phi) * np.maximum(0, x - k_max) ** 3\n",
    "\n",
    "S1_train = spline_basis(x_train, knots, j=1) \n",
    "S2_train = spline_basis(x_train, knots, j=2) \n",
    "S3_train = spline_basis(x_train, knots, j=3) \n",
    "\n",
    "# Spline design matrix \n",
    "D_train = np.transpose(np.vstack([np.ones_like(x_train), x_train, S1_train, S2_train, S3_train]))\n",
    "D_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a0dc90fd-5be6-4267-8520-761764d0c606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 5)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spline_basis_derivative(x, knots, j):\n",
    "    k_min = min(knots)\n",
    "    k_max = max(knots)\n",
    "    phi = (k_max - knots[j]) / (k_max - k_min)\n",
    "    return 3 * np.maximum(0, x - knots[j]) ** 2 - 3 * phi * np.maximum(0, x - k_min) ** 2 - 3 * (1 - phi) * np.maximum(0, x - k_max) ** 2\n",
    "\n",
    "dS1_train = spline_basis_derivative(x_train, knots, j=1) \n",
    "dS2_train = spline_basis_derivative(x_train, knots, j=2) \n",
    "dS3_train = spline_basis_derivative(x_train, knots, j=3) \n",
    "\n",
    "# Derivative spline design matrix \n",
    "dD_train = np.transpose(np.vstack([np.zeros_like(x_train), np.ones_like(x_train), dS1_train, dS2_train, dS3_train]))\n",
    "dD_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2cbaba2c-f2af-48d0-9475-811d697bcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = tf.Variable(tf.random.normal(shape=[1, int(X.shape[1])], mean=0, stddev=1, seed=42))\n",
    "gamma = tf.Variable(tf.random.normal(shape=[1, int(Ds.shape[1])], mean=0, stddev=1, seed=42))\n",
    "\n",
    "X_train_tf = tf.cast(X_train, dtype=tf.float32)\n",
    "D_train_tf = tf.cast(D_train, dtype=tf.float32)\n",
    "dD_train_tf = tf.cast(dD_train, dtype=tf.float32)\n",
    "\n",
    "e_train_tf = tf.cast(e_train[:, None], dtype=tf.float32)\n",
    "t_train_tf = tf.cast(t_train[:, None], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0ac3f4e9-4afe-4914-8b86-00e2a8c39190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5849466323852539\n",
      "Epoch 1, Loss: 0.5039567947387695\n",
      "Epoch 2, Loss: 0.4121197462081909\n",
      "Epoch 3, Loss: 0.3399924635887146\n",
      "Epoch 4, Loss: 0.25428447127342224\n",
      "Epoch 5, Loss: 0.19022883474826813\n",
      "Epoch 6, Loss: 0.12723389267921448\n",
      "Epoch 7, Loss: 0.0855337381362915\n",
      "Epoch 8, Loss: 0.05498019978404045\n",
      "Epoch 9, Loss: 0.04202524572610855\n"
     ]
    }
   ],
   "source": [
    "def loss():    \n",
    "    eta = D_train_tf @ tf.transpose(gamma) + X_train_tf @ tf.transpose(beta)\n",
    " \n",
    "    f1 = 1 / t_train_tf * dD_train_tf @ tf.transpose(gamma) * tf.math.exp(eta - tf.math.exp(eta))\n",
    "    f2 = 1 / (1 + tf.math.exp(eta))\n",
    "\n",
    "    return e_train_tf * f1 + (1 - e_train_tf) * f2\n",
    "    \n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "for epoch in tf.range(10):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss()\n",
    "    \n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(loss_value, [gamma, beta])\n",
    "    \n",
    "    # Apply gradients to update gamma and beta\n",
    "    optimizer.apply_gradients(zip(gradients, [gamma, beta]))\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Loss: {loss_value.numpy().mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c62f46-e073-4c88-ba97-39dc1b3d6af5",
   "metadata": {},
   "source": [
    "# De-centralized setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1be7e1-b595-43d1-a79f-812d12c465be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sksurv.datasets import load_breast_cancer \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset \n",
    "X, y = load_breast_cancer()\n",
    "\n",
    "# Unpack \n",
    "event, duration = zip(*y)\n",
    "e = np.array(event)\n",
    "t = np.array(duration)\n",
    "\n",
    "# Drop columns that are not numerical \n",
    "X = X[X.columns[X.dtypes != \"category\"]]\n",
    "\n",
    "# Train-test splitting \n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(X.shape[0]), test_size=0.25, random_state=42, stratify=e.astype(int)\n",
    ")\n",
    "X_train, X_test = X.iloc[train_idx].to_numpy(), X.iloc[test_idx].to_numpy()\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "e_train, e_test = e[train_idx], e[test_idx]\n",
    "t_train, t_test = t[train_idx], t[test_idx]\n",
    "\n",
    "X_train.shape, X_test.shape "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
