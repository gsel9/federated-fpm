{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6617d2-2952-4ffb-a4b0-5972899444b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sci-hub.se/10.1002/sim.1203\n",
    "# https://journals.sagepub.com/doi/pdf/10.1177/1536867x0900900206"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7d576-a457-41f3-8e9d-af92aeb5b046",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730c43d0-3c00-48d6-abae-c7ed96e55f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>arrest</th>\n",
       "      <th>fin</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>wexp</th>\n",
       "      <th>mar</th>\n",
       "      <th>paro</th>\n",
       "      <th>prio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week  arrest  fin  age  race  wexp  mar  paro  prio\n",
       "0    20       1    0   27     1     0    0     1     3\n",
       "1    17       1    0   18     1     0    0     1     8\n",
       "2    25       1    0   19     0     1    0     1    13\n",
       "3    52       0    1   23     1     1    1     1     1\n",
       "4    52       0    0   19     0     1    0     1     3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "from lifelines.datasets import load_rossi\n",
    "\n",
    "data = load_rossi()\n",
    "data.dropna(inplace=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd8b753-6634-487c-91fb-95646b080c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_col = \"arrest\"\n",
    "duration_col = \"week\"\n",
    "\n",
    "X = data.drop(columns=[event_col, duration_col])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389a577a-786d-4071-8de6-8651153901c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((367, 9), (65, 9))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(data.shape[0]), test_size=0.15, random_state=42, stratify=data[event_col]\n",
    ")\n",
    "data_train, data_test = data.iloc[train_idx], data.iloc[test_idx]\n",
    "X_train, X_test = X.iloc[train_idx].values, X.iloc[test_idx].values\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950c2a6-5ce2-4969-92ae-4f00520ad1c4",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22bb5c99-6b6d-4c0d-a7dc-5177505c803b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((367, 7), (65, 7))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d87c9a-a4f8-4975-a920-0a383669d0d6",
   "metadata": {},
   "source": [
    "# Knots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8092e99d-54dd-4f8c-a274-784f865c149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 3.9512437185814275)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_t_test = np.log(data_test[duration_col])\n",
    "log_t_train = np.log(data_train[duration_col])\n",
    "min(log_t_train), max(log_t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531f96a4-58b3-4dd4-869f-38ad87cacd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 3.9512437185814275)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Knot locations: Centiles of the distribution of **uncensored** log event times\n",
    "# - Boundary knots: placed at the 0th and 100th centiles (min and max values)\n",
    "# - Internal knots: internal knots are placed at the centiles between the min and max   \n",
    "knots = np.percentile(log_t_train[data_train[event_col] == 1], [0, 25, 50, 75, 100])\n",
    "min(knots), max(knots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9604072-b303-457a-ba8d-bde2e4ee3469",
   "metadata": {},
   "source": [
    "# Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df3749e6-01ee-4ff9-8f71-83af7977a29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((367, 4), (367, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return max(x, 0)\n",
    "\n",
    "\n",
    "def spline_basis(x, k_j, k_min, k_max, derivative=False):\n",
    "    \"\"\"Computes the basis function S(x; k_j).\"\"\"\n",
    "    # Scaling coefficient \n",
    "    s = (k_max - k_j) / (k_max - k_min)\n",
    "\n",
    "    if derivative:\n",
    "        # Derivative of the spline basis function\n",
    "        return 3 * relu(x - k_j) ** 2 - 3 * s * relu(x - k_min) ** 2 - 3 * (1 - s) * relu(x - k_max) ** 2\n",
    "\n",
    "    # Spline basis function \n",
    "    return relu(x - k_j) ** 3 - s * relu(x - k_min) ** 3 - (1 - s) * relu(x - k_max) ** 3\n",
    "\n",
    "\n",
    "def spline_design_matrix(ln_t, knots):\n",
    "    \"\"\"Computes the spline function s(x; γ, k).\"\"\"\n",
    "    # Boundary knots\n",
    "    k_min, k_max = knots[0], knots[-1]\n",
    "    # Construct basis functions over internal knots \n",
    "    basis = [spline_basis(ln_t, k_j, k_min, k_max) for k_j in knots[1:-1]]\n",
    "    # Design matrix \n",
    "    return np.array([ln_t] + basis)\n",
    "\n",
    "\n",
    "def spline_derivative_design_matrix(ln_t, knots):\n",
    "    \"\"\"Computes the spline function s(x; γ, k).\"\"\"\n",
    "    # Boundary knots\n",
    "    k_min, k_max = knots[0], knots[-1]\n",
    "    # Construct basis functions over internal knots \n",
    "    basis = [spline_basis(ln_t, k_j, k_min, k_max, derivative=True) for k_j in knots[1:-1]]\n",
    "    # Design matrix \n",
    "    return 1 / np.exp(ln_t) * np.array([1] + basis)\n",
    "\n",
    "\n",
    "def create_splines(log_t, knots):\n",
    "\n",
    "    D, dDdt = [], []\n",
    "    for log_time in log_t:\n",
    "        D.append(spline_design_matrix(log_time, knots))\n",
    "        dDdt.append(spline_derivative_design_matrix(log_time, knots))\n",
    "    \n",
    "    # Cast to <numpy.ndarray>\n",
    "    return np.array(D), np.array(dDdt)\n",
    "\n",
    "\n",
    "D, D_prime = create_splines(log_t_train, knots)\n",
    "D.shape, D_prime.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce72de16-ceee-4f9a-96f4-0bc061966160",
   "metadata": {},
   "source": [
    "# Parameter initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c14b1a2-c012-4758-8484-9aa1203864b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_train = data_train[event_col].values[:, None]\n",
    "delta_test = data_test[event_col].values[:, None]\n",
    "delta_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e9d57d-c402-4fec-8706-1c67186e9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "beta0 = np.random.random((1, X.shape[1]))\n",
    "gamma0 = np.random.random((1, D.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db96aaf0-37d8-45c1-a7b4-a97670939ff6",
   "metadata": {},
   "source": [
    "# Fitting centralized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6f42390-54bf-4d11-b640-9631fa328efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.65450862, -13.25046945,  -8.04299769,  -2.34127952])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_gamma(gamma, beta, delta, D, D_prime, X):\n",
    "    phi = D @ gamma.T + X_train @ beta.T\n",
    "\n",
    "    ds_dt = D_prime @ gamma.T\n",
    "\n",
    "    return delta * (D + D_prime / ds_dt) + np.exp(phi) * D\n",
    "\n",
    "\n",
    "grad_gamma = gradient_gamma(gamma0, beta0, delta_train, D, D_prime, X_train)\n",
    "grad_gamma[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "336d2e55-2853-472b-afc8-e2520cdf6e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.98648792, -0.27112942,  0.37856055,  0.8791921 ,  2.78180058,\n",
       "        0.78988578,  0.3479128 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_beta(gamma, beta, delta, D, D_prime, X):\n",
    "    phi = D @ gamma.T + X_train @ beta.T\n",
    "\n",
    "    return X * (delta + np.exp(phi))\n",
    "\n",
    "\n",
    "grad_beta = gradient_beta(gamma0, beta0, delta_train, D, D_prime, X_train)\n",
    "grad_beta[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ab8843-487d-49b6-bcb4-d4fe63151c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-47.63031386])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_likelihood(gamma, beta, delta, D, D_prime, X):\n",
    "    phi = D @ gamma.T + X_train @ beta.T\n",
    "\n",
    "    ds_dt = np.clip(D_prime @ gamma.T, 1e-16, np.inf)\n",
    "\n",
    "    return delta * (phi + np.log(ds_dt)) + np.exp(phi)\n",
    "\n",
    "\n",
    "log_l = log_likelihood(gamma0, beta0, delta_train, D, D_prime, X_train)\n",
    "log_l[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efbf500e-3ebf-4fec-ab1c-07930814d926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.41476774046744463, 12742, 17986, 35, 1080)\n",
      "(0.2907465825446898, 276, 674, 1, 0)\n",
      "(0.41454019438936385, 12735, 17993, 35, 1080)\n",
      "(0.2886435331230284, 274, 676, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "def learning_rate_sched(epoch, init_lr=0.01, total_epochs=10):\n",
    "    \"Learning rate scheduler\"\n",
    "    return init_lr * 0.5 * (1 + np.cos(np.pi * epoch / total_epochs)) \n",
    "\n",
    "\n",
    "# Initialize parameters \n",
    "gamma = gamma0.copy()\n",
    "beta = beta0.copy()\n",
    "\n",
    "total_epochs = 10\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    learning_rate = learning_rate_sched(epoch, init_lr=0.01, total_epochs=total_epochs)\n",
    "\n",
    "    grad_gamma = gradient_gamma(gamma, beta, delta_train, D, D_prime, X_train).mean(axis=0)\n",
    "    grad_beta = gradient_beta(gamma, beta, delta_train, D, D_prime, X_train).mean(axis=0)\n",
    "\n",
    "    # Minimizing the negative log-likelihood\n",
    "    gamma_new = gamma - learning_rate * grad_gamma.mean(axis=0)\n",
    "    beta_new = beta - learning_rate * grad_beta.mean(axis=0)\n",
    "\n",
    "    gamma = gamma_new \n",
    "    beta = beta_new \n",
    "    \n",
    "    #if np.linalg.norm(gamma_new - gamma) / np.linalg.norm(gamma) > 1e-4:\n",
    "    #    gamma = gamma_new \n",
    "\n",
    "    #if np.linalg.norm(beta_new - beta) / np.linalg.norm(beta) > 1e-4:\n",
    "    #    beta = beta_new \n",
    "\n",
    "# Baseline\n",
    "print(concordance_index_censored(delta_train.astype(bool).squeeze(), np.exp(log_t_train), (X_train @ beta0.T).squeeze()))\n",
    "print(concordance_index_censored(delta_test.astype(bool).squeeze(), np.exp(log_t_test), (X_test @ beta0.T).squeeze()))\n",
    "\n",
    "# Fitted model \n",
    "print(concordance_index_censored(delta_train.astype(bool).squeeze(), np.exp(log_t_train), (X_train @ beta.T).squeeze()))\n",
    "print(concordance_index_censored(delta_test.astype(bool).squeeze(), np.exp(log_t_test), (X_test @ beta.T).squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f971f383-a66c-45f9-9f8c-43b56165868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.41476774046744463, 12742, 17986, 35, 1080)\n",
      "(0.2907465825446898, 276, 674, 1, 0)\n",
      "(0.40270779832916165, 12371, 18357, 35, 1080)\n",
      "(0.2949526813880126, 280, 670, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "total_epochs = 10\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "gamma_var = tf.Variable(gamma0, dtype=tf.float32)\n",
    "beta_var = tf.Variable(beta0, dtype=tf.float32)  \n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    \n",
    "    grad_gamma = gradient_gamma(gamma, beta, delta_train, D, D_prime, X_train).sum(axis=0)\n",
    "    grad_beta = gradient_beta(gamma, beta, delta_train, D, D_prime, X_train).sum(axis=0)\n",
    "\n",
    "    gradients = [tf.cast(grad_beta, dtype=tf.float32), tf.cast(grad_gamma, dtype=tf.float32)]\n",
    "    # Apply gradients to update gamma and beta\n",
    "    optimizer.apply_gradients(zip(gradients, [beta_var, gamma_var]))\n",
    "    gamma = gamma_var.numpy()\n",
    "    beta = beta_var.numpy() \n",
    "\n",
    "# Baseline\n",
    "print(concordance_index_censored(delta_train.astype(bool).squeeze(), np.exp(log_t_train), (X_train @ beta0.T).squeeze()))\n",
    "print(concordance_index_censored(delta_test.astype(bool).squeeze(), np.exp(log_t_test), (X_test @ beta0.T).squeeze()))\n",
    "\n",
    "# Fitted model \n",
    "print(concordance_index_censored(delta_train.astype(bool).squeeze(), np.exp(log_t_train), (X_train @ beta.T).squeeze()))\n",
    "print(concordance_index_censored(delta_test.astype(bool).squeeze(), np.exp(log_t_test), (X_test @ beta.T).squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d1d71-0d4a-4e4e-af6e-c6b35b9e50ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
