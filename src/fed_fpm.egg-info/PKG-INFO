Metadata-Version: 2.1
Name: fed-fpm
Version: 0.0.1
Summary: Federated flexible parametric models.
Author: Severin Elvatun
Author-email: langberg91@gmail.com
License: MIT
Platform: any
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Intended Audience :: Science/Research
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown; charset=UTF-8
Requires-Dist: scikit-learn>=1.0
Requires-Dist: numpy
Requires-Dist: pydantic<2.0
Requires-Dist: scipy
Requires-Dist: pandas
Provides-Extra: testing
Requires-Dist: setuptools; extra == "testing"
Requires-Dist: pytest; extra == "testing"
Requires-Dist: pytest-cov; extra == "testing"
Requires-Dist: jupyter; extra == "testing"
Requires-Dist: notebook; extra == "testing"
Requires-Dist: bandit; extra == "testing"
Requires-Dist: black; extra == "testing"
Requires-Dist: black-nb; extra == "testing"
Requires-Dist: darglint; extra == "testing"
Requires-Dist: docutils<0.18; extra == "testing"
Requires-Dist: doc8; extra == "testing"
Requires-Dist: flake8; extra == "testing"
Requires-Dist: isort; extra == "testing"
Requires-Dist: nbconvert; extra == "testing"
Requires-Dist: nbformat; extra == "testing"
Requires-Dist: pytest-benchmark; extra == "testing"
Requires-Dist: pytest-xdist[psutil]; extra == "testing"
Requires-Dist: pytest-xprocess; extra == "testing"
Requires-Dist: igraph; extra == "testing"
Requires-Dist: py; extra == "testing"
Requires-Dist: pre-commit; extra == "testing"
Requires-Dist: tabulate; extra == "testing"
Requires-Dist: click; extra == "testing"
Provides-Extra: all
Requires-Dist: importlib-metadata; python_version < "3.8" and extra == "all"
Requires-Dist: setuptools; extra == "all"
Requires-Dist: pytest; extra == "all"
Requires-Dist: pytest-cov; extra == "all"
Requires-Dist: jupyter; extra == "all"
Requires-Dist: notebook; extra == "all"
Requires-Dist: bandit; extra == "all"
Requires-Dist: black; extra == "all"
Requires-Dist: black-nb; extra == "all"
Requires-Dist: darglint; extra == "all"
Requires-Dist: docutils<0.18; extra == "all"
Requires-Dist: doc8; extra == "all"
Requires-Dist: flake8; extra == "all"
Requires-Dist: isort; extra == "all"
Requires-Dist: nbconvert; extra == "all"
Requires-Dist: nbformat; extra == "all"
Requires-Dist: pytest-benchmark; extra == "all"
Requires-Dist: pytest-xdist[psutil]; extra == "all"
Requires-Dist: pytest-xprocess; extra == "all"
Requires-Dist: igraph; extra == "all"
Requires-Dist: py; extra == "all"
Requires-Dist: pre-commit; extra == "all"
Requires-Dist: tabulate; extra == "all"
Requires-Dist: click; extra == "all"

# Federated flexible parametric models 

- I mentioned about usability and the potential need to be able to transfer model estimates into Stata and/or R, so that the various postestimation tools can be used. 
- I wrote a Stata command (mlad) when I was stuck in England during COVID that combined Stata’s optimizer (ml) with performing computational intensive calculations in Python.
- The reason for the switch to Python was to use the JAX module (https://jax.readthedocs.io/en/latest/index.html) that could (1) make use of the automatic differentiation within JAX and (2) use all available CPUs (and in theory GPUs, but I never tested this).
- I mention this because although Python was doing the heavy work in terms of computation – the returned model was exactly as Stata expected to see, so immediately usable with various postestimation utilities.
- I will not go into details, but at the start of each iteration I passed the current estimates of the parameters from Stata to Python (a 1 x p vector). Python then calculated the following.
  - The value of the log likelihood (a scalar)
  - The score (gradient) vector (a 1 x p vector)
  - The Hessian (second derivatives) matrix (a p x p matrix).

    These were then passed to Stata.
    Stata then updated the parameter estimates (using the Newton-Raphson algorithm) and returned the updated vector of parameters to Python.
    In terms of federated analysis, I assume that you are using an optimizer in Python and probably need these 3 things anyway (or they are automatically calculated within the optimizer) so in theory these could be passed back to Stata in the same way that I have done. 
